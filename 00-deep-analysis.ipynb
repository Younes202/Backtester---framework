{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa71333-81a4-424a-8083-a6b9237d64e6",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f0c92be7-975c-438a-beaf-8a29c6cea470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import talib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0924796-905d-4467-bac6-3cd9fbcf9f62",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "311e4b5e-a431-4ca4-a985-6bc76e7a29de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each CSV file into a DataFrame\n",
    "df_15m = pd.read_csv('spot_klines_data/BTCUSDT_15m_2024-2025.csv')\n",
    "df_1d = pd.read_csv('spot_klines_data/BTCUSDT_1d_2024-2025.csv')\n",
    "df_1m = pd.read_csv('spot_klines_data/BTCUSDT_1m_2024-2025.csv')\n",
    "df_1w = pd.read_csv('spot_klines_data/BTCUSDT_1w_2024-2025.csv')\n",
    "df_5m = pd.read_csv('spot_klines_data/BTCUSDT_5m_2024-2025.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f4185-e3b7-4fdf-8ac9-310c834946ec",
   "metadata": {},
   "source": [
    "# Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "eb368a51-f063-4e24-8971-512a531a206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy:\n",
    "    def __init__(self, data, timeframe_type):\n",
    "        self.data = data  # DataFrame containing historical price data\n",
    "        self.timeframe_type = timeframe_type  # 'long' or 'short'\n",
    "\n",
    "    def calculate_indicators(self):\n",
    "        # Based on timeframe_type, select appropriate indicators\n",
    "        if self.timeframe_type == 'trend':  # Long-term timeframes like 1D, 1W\n",
    "            self.data['EMA50'] = ta.ema(self.data['close'], length=50)\n",
    "            self.data['EMA200'] = ta.ema(self.data['close'], length=200)\n",
    "\n",
    "            self.data['RSI'] = ta.rsi(self.data['close'], length=14)\n",
    "            self.data['Volume'] = self.data['volume']  # Volume might not need to be calculated\n",
    "    \n",
    "        elif self.timeframe_type == 'intraday':  # Short-term timeframes like 1m, 15m, 1H\n",
    "            self.data['RSI'] = ta.rsi(self.data['close'], length=7)\n",
    "            \n",
    "            macd_values = ta.macd(self.data['close'])\n",
    "            self.data['MACD'] = macd_values['MACD_12_26_9']\n",
    "            self.data['MACD_signal'] = macd_values['MACDs_12_26_9']\n",
    "            self.data['MACD_prev'] = self.data['MACD'].shift(1)\n",
    "            self.data['MACD_signal_prev'] = self.data['MACD_signal'].shift(1)\n",
    "\n",
    "\n",
    "        elif self.timeframe_type == 'confirmation':  \n",
    "            self.data['RSI'] = ta.rsi(self.data['close'], length=7)\n",
    "            macd_values = ta.macd(self.data['close'])\n",
    "            self.data['MACD'] = macd_values['MACD_12_26_9']\n",
    "            self.data['MACD_signal'] = macd_values['MACDs_12_26_9']\n",
    "            self.data['EMA9'] = ta.ema(self.data['close'], length=9)\n",
    "            self.data['EMA21'] = ta.ema(self.data['close'], length=21)\n",
    "        else:\n",
    "            return None\n",
    "        return self.data\n",
    "\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Drop NaN values after adding indicators\n",
    "        self.data.dropna(inplace=True)\n",
    "        return self.data\n",
    "\n",
    "    def get_decision(self):\n",
    "        self.calculate_indicators()\n",
    "        self.preprocess_data()\n",
    "    \n",
    "        if self.data.empty:\n",
    "            raise ValueError(\"Error: DataFrame is empty before setting signals.\")\n",
    "    \n",
    "        self.data['Signal'] = 0  # Default value\n",
    "    \n",
    "        if self.timeframe_type == 'trend':\n",
    "            self.data.loc[(self.data['EMA50'] > self.data['EMA200']) & \n",
    "                          (self.data['RSI'] > 50) & (self.data['RSI'] < 70), 'Signal'] = 1\n",
    "    \n",
    "        elif self.timeframe_type == 'intraday':\n",
    "            self.data.loc[(self.data['RSI'] < 30) & (self.data['MACD'] > self.data['MACD_signal']), 'Signal'] = 1\n",
    "    \n",
    "        elif self.timeframe_type == 'confirmation':\n",
    "            self.data.loc[(self.data['RSI'] < 30) & (self.data['MACD'] > self.data['MACD_signal']), 'Signal'] = 1\n",
    "    \n",
    "        return self.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd078573-fff6-40ac-8cc7-010639e9c207",
   "metadata": {},
   "source": [
    "# Fetch and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0fa10831-b5eb-44f4-8b90-370e9ad1141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_process_data(data, timeframe, close_time, augmentation=0):\n",
    "    \"\"\"\n",
    "    Fetch and process data for a given timeframe and close_time.\n",
    "\n",
    "    Parameters:\n",
    "        data (str or pd.DataFrame): Path to CSV file or a DataFrame containing historical data.\n",
    "        timeframe (str): Timeframe (e.g., \"1m\", \"5m\", \"1h\", \"1d\", \"1w\").\n",
    "        close_time (str or datetime): The end time for data selection.\n",
    "        augmentation (int): Number of additional data points to include after 200.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered dataset containing the last 200 + augmentation points.\n",
    "    \"\"\"\n",
    "    # Load data if it's a file path\n",
    "    if isinstance(data, str):\n",
    "        df = pd.read_csv(data)\n",
    "    elif isinstance(data, pd.DataFrame):\n",
    "        df = data.copy()\n",
    "    else:\n",
    "        raise ValueError(\"`data` must be a file path (str) or a pandas DataFrame.\")\n",
    "\n",
    "    # Ensure 'close_time' column exists\n",
    "    if 'close_time' not in df.columns:\n",
    "        raise KeyError(\"Missing 'close_time' column in the dataset.\")\n",
    "\n",
    "    # Convert 'close_time' to datetime\n",
    "    df['close_time'] = pd.to_datetime(df['close_time'])\n",
    "    close_time = pd.to_datetime(close_time)\n",
    "\n",
    "    # Define timeframe intervals\n",
    "    timeframe_intervals = {\n",
    "        \"1m\": \"T\",    # Minute\n",
    "        \"5m\": \"5T\",   # 5 Minutes\n",
    "        \"15m\": \"15T\", # 15 Minutes\n",
    "        \"30m\": \"30T\", # 30 Minutes\n",
    "        \"1h\": \"H\",    # Hour\n",
    "        \"4h\": \"4H\",   # 4 Hours\n",
    "        \"1d\": \"D\",    # Day\n",
    "        \"1w\": \"W\"     # Week\n",
    "    }\n",
    "\n",
    "    if timeframe not in timeframe_intervals:\n",
    "        raise ValueError(f\"Unsupported timeframe: {timeframe}\")\n",
    "\n",
    "    # Step 1: Fetch 200 historical data points (before or at `close_time`)\n",
    "    df_past = df[df['close_time'] <= close_time].sort_values(by='close_time', ascending=False).head(200)\n",
    "    \n",
    "    # Step 2: Fetch additional `augmentation` points after `close_time`\n",
    "    df_future = df[df['close_time'] > close_time].sort_values(by='close_time', ascending=True).head(augmentation)\n",
    "\n",
    "    # Combine past and future data\n",
    "    df_final = pd.concat([df_past, df_future]).sort_values(by='close_time', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe433c53-34b4-4b88-ad05-3ad77e53f984",
   "metadata": {},
   "source": [
    "# Apply Strategy with a Scheduling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "04044acd-e68c-4c05-b05f-22eb4d5259d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32851"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startegy = Strategy(df_5m, timeframe_type=\"trend\")\n",
    "df = startegy.get_decision()\n",
    "positives = df[df[\"Signal\"] == 1]\n",
    "\n",
    "collected_ = fetch_and_process_data(data, timeframe, close_time, augmentation=1)\n",
    "len(collected_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d37a77-5f8d-44f6-b07e-c5e2519988f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
